{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16cb1bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fe1bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets links from a webpage\n",
    "def get_site_links(base_url, common_part_of_url):\n",
    "    links = []\n",
    "    res = requests.get(base_url, headers ={\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \" +\n",
    "                    \"AppleWebKit/537.36 (KHTML, like Gecko) \" +\n",
    "                    \"Chrome/114.0.0.0 Safari/537.36\"\n",
    "    })\n",
    "    soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "\n",
    "    for a in soup.find_all(\"a\", href=True):\n",
    "        href = a[\"href\"]\n",
    "        if(href.startswith(common_part_of_url)):\n",
    "            links.append(href)\n",
    "\n",
    "    time.sleep(1)\n",
    "    return list(set(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5f2bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracts necessary info from webpage\n",
    "def scrape_vox_article(url):\n",
    "    res = requests.get(url, headers ={\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \" +\n",
    "                  \"AppleWebKit/537.36 (KHTML, like Gecko) \" +\n",
    "                  \"Chrome/114.0.0.0 Safari/537.36\"\n",
    "    })\n",
    "    soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "\n",
    "    # Try to find the content block\n",
    "    article_divs = soup.find_all(\"div\", class_ = \"elementor-widget-container\") #specific for vox iitk\n",
    "\n",
    "    paragraphs = []\n",
    "    for div in article_divs:\n",
    "        for p in div.find_all(\"p\"):\n",
    "            text = p.get_text(strip=True)\n",
    "            if text:  # skip empty\n",
    "                paragraphs.append(text)\n",
    "\n",
    "    content = \"\\n\".join(paragraphs)\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8526ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting chunks of data\n",
    "base_links = ['https://voxiitk.com/category/all-about-iitk/', 'https://voxiitk.com/category/all-about-iitk/page/2', 'https://voxiitk.com/category/all-about-iitk/page/3', 'https://voxiitk.com/category/all-about-iitk/page/4', 'https://voxiitk.com/category/all-about-iitk/page/5', 'https://voxiitk.com/category/editorials/', 'https://voxiitk.com/category/flagship-series/page/', 'https://voxiitk.com/category/flagship-series/page/2', 'https://voxiitk.com/category/flagship-series/page/3', 'https://voxiitk.com/category/flagship-series/page/4', 'https://voxiitk.com/category/flagship-series/page/5', 'https://voxiitk.com/category/flagship-series/page/6', 'https://voxiitk.com/category/reports-and-investigations/page/', 'https://voxiitk.com/category/reports-and-investigations/page/2', 'https://voxiitk.com/category/surveys/', 'https://voxiitk.com/category/beyond-iitk/', 'https://voxiitk.com/category/flagship-series/iitk-101/']\n",
    "\n",
    "big_chunks = []\n",
    "for base_link in base_links:\n",
    "    links = get_site_links(base_link, 'https://voxiitk.com')\n",
    "    for url in links:\n",
    "        big_chunks.append(scrape_vox_article(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1c9f1bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "857\n"
     ]
    }
   ],
   "source": [
    "print(len(big_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0883a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\shilp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\shilp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# chunkifying function which shortens data chunks to processable ones \n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "def chunk_text(text, max_words=400, overlap=100):\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_word_count = 0\n",
    "\n",
    "    i = 0\n",
    "    while i < len(sentences):\n",
    "        sentence = sentences[i]\n",
    "        word_count = len(word_tokenize(sentence))\n",
    "\n",
    "        if current_word_count + word_count <= max_words:\n",
    "            current_chunk.append(sentence)\n",
    "            current_word_count += word_count\n",
    "            i += 1\n",
    "        else:\n",
    "            # Save chunk\n",
    "            chunk_text = ' '.join(current_chunk).strip()\n",
    "            chunks.append(chunk_text)\n",
    "\n",
    "            # Move back overlap words\n",
    "            if overlap > 0:\n",
    "                backtrack_words = 0\n",
    "                backtrack_index = len(current_chunk) - 1\n",
    "                while backtrack_index >= 0 and backtrack_words < overlap:\n",
    "                    backtrack_words += len(word_tokenize(current_chunk[backtrack_index]))\n",
    "                    backtrack_index -= 1\n",
    "                current_chunk = current_chunk[backtrack_index+1:]\n",
    "                current_word_count = sum(len(word_tokenize(s)) for s in current_chunk)\n",
    "            else:\n",
    "                current_chunk = []\n",
    "                current_word_count = 0\n",
    "\n",
    "    # Save any remaining chunk\n",
    "    if current_chunk:\n",
    "        chunks.append(' '.join(current_chunk).strip())\n",
    "\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9eb33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunkifying: 100%|██████████| 857/857 [00:10<00:00, 84.50it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Disclaimer: Vox Populi, IIT Kanpur, is the exclusive owner of the information on this website. No part of this content may be duplicated, paraphrased, or interpreted in any other way without written consent from Vox Populi. If you want to reproduce any of the content on this page, please contact our chief editors directly or reach out to us by email atvoxpopuli@iitk.ac.in. On February 19, 2025, the Council of Students for Hostel Affairs (CoSHA) held its second emergency meeting in the Senate Hall to discuss the recent eviction notice served to the Dhobis, whose deadline to vacate was set for March 6. This meeting was attended by Hall Presidents, Gymkhana representatives and a number of GBMs. According to the published minutes, “The central theme of the discussion was that the students, being the majority stakeholders of the service, were never consulted before the eviction notices were served to the Dhobis.”\\nThe institute’s long-term modernization plan was a topic of discussion. The Director’s proposal (as reported previously), which involved establishing a central laundromat with industrial-grade washing machines operated by the Dhobis, was unanimously opposed. As recorded in the minutes, “As part of a long-term modernization plan, the institute wanted to eventually set up a central laundromat with industrial grade washing machines operated by the dhobis themselves. The CoSHA, representative of the student body, was unanimous in its disagreement with the same, citing reasons of hygiene, convenience and concerns of privatization.”\\nThe basis for the eviction was another focal point. The notice deemed Dhobi Ghat unsafe for residence based on two reports—from the Structural Engineering Laboratory of IIT Kanpur and the Department of Civil Engineering at HBTU. The minutes note, “It was noted that neither of the two reports were made available to the GBM to see and…\\xa0 stated that despite emails sent to 9 professors concerned with the above two bodies by Vox Populi, six of them failed to acknowledge the existence of the reports and three did not reply.', 'The CoSHA, representative of the student body, was unanimous in its disagreement with the same, citing reasons of hygiene, convenience and concerns of privatization.”\\nThe basis for the eviction was another focal point. The notice deemed Dhobi Ghat unsafe for residence based on two reports—from the Structural Engineering Laboratory of IIT Kanpur and the Department of Civil Engineering at HBTU. The minutes note, “It was noted that neither of the two reports were made available to the GBM to see and…\\xa0 stated that despite emails sent to 9 professors concerned with the above two bodies by Vox Populi, six of them failed to acknowledge the existence of the reports and three did not reply. The Chairperson, CoSHA then confirmed that he and the Chairperson, Students’ Senate had seen the report from the HBTU but not the other report.”\\nOn the idea of using hall-14 for the storage of clothes, the minutes state, “The CoSHA agreed that rooms in Hall 14 would never be an option as firstly the sparse quantity was not enough for the Dhobis to carry out daily work and secondly as student intake will increase over the years the Dhobis would gradually be forced out again.”\\nConcerns were also raised about the manner in which the eviction notices were served. One entry in the minutes reads, “It was pointed out that despite the institute acknowledging its humanitarian obligation towards the Dhobis, they were always threatened with ultimatums, police threats, and a large swath of security guards always accompanying the people serving the notices. They were also told that bulldozers would be used if they did not vacate.”\\nLastly, a discrepancy in official communications was discussed saying that “GBMs present in the meeting pointed out a major incident where an English version of a letter given by the institute directly contradicted the Hindi version and how the legal authorities would only consider the English version in case of any discrepancy.', 'One entry in the minutes reads, “It was pointed out that despite the institute acknowledging its humanitarian obligation towards the Dhobis, they were always threatened with ultimatums, police threats, and a large swath of security guards always accompanying the people serving the notices. They were also told that bulldozers would be used if they did not vacate.”\\nLastly, a discrepancy in official communications was discussed saying that “GBMs present in the meeting pointed out a major incident where an English version of a letter given by the institute directly contradicted the Hindi version and how the legal authorities would only consider the English version in case of any discrepancy. This contradiction in the notices was dismissed as ‘a typo’ by the institute.”\\nThe CoSHA, in its meeting on the 19th of February, 2025, keeping the best interest of the students in retaining the washerman services, decided unanimously the following courses of action henceforth. (i) A two way GBM between the dhobis and students where they could discuss the student stance adopted in this meeting. (ii) A three way Open House between the Dhobis (Service givers), Students (Service receivers) and the Director must be held before their eviction on the 6th of March, 2025. (iii) The students would not accept any alternative for the dhobi services in the near future, and the student representatives would present a stance of dissent against automation in this regard. (iv) The students, as the receivers of the service, would not accept the institute administration acting without listening to their stance on the matter. The CoSHA and its members present the following points to the administration after consultation with the Dhobis in the two way GBM:\\nThe next day, student representatives met with the Dhobis to confirm their support for the demands outlined in the CoSHA meeting, which the Dhobis affirmed. Later that evening, hall presidents and the PSG Chair met with the Director to discuss the proceedings\\nAccording to a Gymkhana representative present at the meeting, the Director rejected the students’ opposition to mechanization and reaffirmed that modernization was essential for sustainability.', '(iv) The students, as the receivers of the service, would not accept the institute administration acting without listening to their stance on the matter. The CoSHA and its members present the following points to the administration after consultation with the Dhobis in the two way GBM:\\nThe next day, student representatives met with the Dhobis to confirm their support for the demands outlined in the CoSHA meeting, which the Dhobis affirmed. Later that evening, hall presidents and the PSG Chair met with the Director to discuss the proceedings\\nAccording to a Gymkhana representative present at the meeting, the Director rejected the students’ opposition to mechanization and reaffirmed that modernization was essential for sustainability. Students also maintained that Hall 14 was not a viable storage space for the Dhobis. One of the Hall Presidents suggested setting up of tin sheds for storage of clothes, as the existing godowns had been declared structurally unsafe in the reports. Currently, sixteen six-foot-by-six-foot tin shed structures have been erected at one end of Dhobi Ghat. Tin Sheds erected at one end of Dhobi Ghat\\nOn March 4, student representatives, professors, and several GBMs gathered at Dhobi Ghat to discuss the evolving situation. The meeting concluded with three unanimously agreed points –\\nIn addition to these demands, those present at the meeting demanded that the Senate convene an emergency meeting to pass a resolution on the issue. Gymkhana representatives acknowledged the existence of this channel, but also added that the proceedings of CoSHA themselves serve as a strong expression of student opinion and demands. The following day (5th March), President, Students Gymkhana informed the senate via mail that \\xa0“the Director has officially confirmed the postponement of the Dhobis’ eviction deadline until a proper dialogue between the administrators and Dhobis is held, in the presence of the Director and students upon his return to campus.”\\nOn March 8, 2025, a meeting was convened in the Faculty Building to address the ongoing Dhobi issue. In contrast to earlier demands for an open house session, the meeting was open to Dhobis and 4 Gymkhana representatives only.', 'The following day (5th March), President, Students Gymkhana informed the senate via mail that \\xa0“the Director has officially confirmed the postponement of the Dhobis’ eviction deadline until a proper dialogue between the administrators and Dhobis is held, in the presence of the Director and students upon his return to campus.”\\nOn March 8, 2025, a meeting was convened in the Faculty Building to address the ongoing Dhobi issue. In contrast to earlier demands for an open house session, the meeting was open to Dhobis and 4 Gymkhana representatives only. Senior officials including the Director, Deputy Director, DoSA, DoAd, and the Registrar were also present. We spoke to a gymkhana representative to understand what was discussed in the meeting. Key points included:\\nIn summary, the three key demands outlined in the CoSHA meeting—\\nWerenotaccepted by the Director and other officials. Neither the student representatives nor the Dhobi community agreed to the proposals presented at the meeting. Both groups confirmed that further internal discussions are needed before reaching any final decision. The Director concluded by agreeing to send an official email to the campus community by the following day. The email is expected to detail the complete history of the issue, outline the current situation, and present the administration’s future plans, thereby ensuring transparency and addressing any communication gaps. As of today, students have not received\\xa0 this mail by the Director. On March 9th, four cameras had been installed at Dhobhighat—three near the drying sites and one at the entrance. With no toilet facilities available, Dhobis are forced to use open spaces for defecation and have objected to the camera placements, arguing that these installations restrict the areas they rely on for this basic need. Until further updates, thedemolition is set to begin tomorrow.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# chunking data\n",
    "from tqdm import tqdm\n",
    "\n",
    "small_chunks = []\n",
    "for chonkies in tqdm(big_chunks, desc=\"Chunkifying\"):\n",
    "    for small_chonkies in chunk_text(chonkies):\n",
    "        small_chunks.append(small_chonkies)\n",
    "\n",
    "print(small_chunks[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fdf8266e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3113\n"
     ]
    }
   ],
   "source": [
    "print(len(small_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c7615b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning function\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "def clean_chunk(raw_html):\n",
    "    # removing html code\n",
    "    soup = BeautifulSoup(raw_html, \"html.parser\")\n",
    "    text = soup.get_text(separator=\" \") \n",
    "\n",
    "    # normalising unicode\n",
    "    text = unicodedata.normalize(\"NFKC\", text)\n",
    "\n",
    "    # removing urls and emails\n",
    "    text = re.sub(r\"http\\S+|www\\.\\S+\", \"\", text)\n",
    "    text = re.sub(r\"\\S+@\\S+\", \"\", text)\n",
    "\n",
    "    # fix bad spacing\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "    # fix punctuation\n",
    "    text = re.sub(r\"\\.([A-Z])\", r\". \\1\", text)\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf87044",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning data\n",
    "for i in range(len(small_chunks)):\n",
    "    small_chunks[i] = clean_chunk(small_chunks[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2ae0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding data to dataset\n",
    "import json \n",
    "import os\n",
    "if os.path.exists(\"dataset.json\"):\n",
    "    with open(\"dataset.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "else:\n",
    "    data = []\n",
    "\n",
    "data.extend(small_chunks)\n",
    "\n",
    "with open(\"dataset.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, indent=2, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kitty",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
